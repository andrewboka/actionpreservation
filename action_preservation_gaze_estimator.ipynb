{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "action_preservation_gaze_estimator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tlPpeznnW3G"
      },
      "source": [
        "Action preservation measure using gaze estimation from\n",
        "https://github.com/glefundes/mobile-face-gaze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQW7hZ-z3I5n"
      },
      "source": [
        "# pip install scikit-video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTd4g8oyiJuo"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import utils\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from models import gazenet\n",
        "from mtcnn import FaceDetector\n",
        "from mtcnn.visualization_utils import show_bboxes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import skvideo.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEt4QCs8iP4H"
      },
      "source": [
        "# Insert file path to unfiltered video\n",
        "unfiltered = skvideo.io.vread(\"T002_ActionsShorter_mini_3239_3347_Use-Radio-or-Gadget.mp4\")  \n",
        "plt.imshow(unfiltered[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNKTI-n5iSZS"
      },
      "source": [
        "# Insert file path to filtered video\n",
        "filtered = skvideo.io.vread(\"submission_example.mp4\")  \n",
        "plt.imshow(filtered[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzLosFKtkq1d"
      },
      "source": [
        "# Ensure that the dimensions are the same\n",
        "print(unfiltered.shape)\n",
        "print(filtered.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV74kFtokrtt"
      },
      "source": [
        "#Preprocess the videos if necessary to ensure dimensions match\n",
        "diff_frame = unfiltered.shape[1] - filtered.shape[1]\n",
        "offset = int(diff_frame/2)\n",
        "unfiltered = unfiltered[:, offset:-offset, offset:-offset, :]\n",
        "print(unfiltered.shape)\n",
        "print(filtered.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfvRxzSSktdZ"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-bRrzOk_TE"
      },
      "source": [
        "model = gazenet.GazeNet(device)\n",
        "state_dict = torch.load('models/weights/gazenet.pth', map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "print('Loaded model on {}'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO1-LTrskwwO"
      },
      "source": [
        "image_u = Image.fromarray(unfiltered[0])\n",
        "face_detector = FaceDetector(device=device)\n",
        "bboxes, landmarks = face_detector.detect(image_u)\n",
        "image_bboxes = show_bboxes(image_u, bboxes, landmarks, width=1, eyeline=True)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image_bboxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYghPISHk1SL"
      },
      "source": [
        "image_f = Image.fromarray(filtered[0])\n",
        "image_bboxes = show_bboxes(image_f, bboxes, landmarks, width=1, eyeline=True)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(image_bboxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KRwEDbkk3mc"
      },
      "source": [
        "fig=plt.figure(figsize=(10, 10))\n",
        "rows = np.ceil(np.sqrt(len(bboxes)))\n",
        "columns = rows + 1\n",
        "plot_idx = 1\n",
        "faces_u, origins_u = [],[]\n",
        "for bbox, lm in zip(bboxes, landmarks):\n",
        "    # Detection confidence check\n",
        "    if(bbox[-1] > 0.98):\n",
        "        # Crop and normalize face\n",
        "        face_u, gaze_origin_u, M_u  = utils.normalize_face(lm, np.asarray(image_u))\n",
        "        faces_u.append(face_u)\n",
        "        origins_u.append(gaze_origin_u)\n",
        "        fig.add_subplot(rows, columns, plot_idx)\n",
        "        plt.imshow(face_u)\n",
        "        plot_idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niev7OPYk4VK"
      },
      "source": [
        "fig=plt.figure(figsize=(10, 10))\n",
        "rows = np.ceil(np.sqrt(len(bboxes)))\n",
        "columns = rows + 1\n",
        "plot_idx = 1\n",
        "faces_f, origins_f = [],[]\n",
        "for bbox, lm in zip(bboxes, landmarks):\n",
        "    # Detection confidence check\n",
        "    if(bbox[-1] > 0.98):\n",
        "        # Crop and normalize face\n",
        "        face_f, gaze_origin_f, M_f  = utils.normalize_face(lm, np.asarray(image_f))\n",
        "        faces_f.append(face_f)\n",
        "        origins_f.append(gaze_origin_f)\n",
        "        fig.add_subplot(rows, columns, plot_idx)\n",
        "        plt.imshow(face_f)\n",
        "        plot_idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-j_46UDk64-"
      },
      "source": [
        "display = np.asarray(image_u)\n",
        "for face_u, gaze_origin_u in zip(faces_u, origins_u):\n",
        "    # Predict gaze\n",
        "    with torch.no_grad():\n",
        "        gaze_u = model.get_gaze(face_u)\n",
        "        gaze_u = gaze_u[0].data.cpu()\n",
        "        display = cv2.circle(display, gaze_origin_u, 1, (0, 255, 0), -1)            \n",
        "        display = utils.draw_gaze(display, gaze_origin_u, gaze_u, length=100, color=(255,0,0), thickness=1)\n",
        "        print(gaze_origin_u)\n",
        "        print(gaze_u)\n",
        "fig=plt.figure(figsize=(10, 10))\n",
        "plt.imshow(display)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f18VqoIjlE1O"
      },
      "source": [
        "display = np.asarray(image_f)\n",
        "for face_f, gaze_origin_f in zip(faces_f, origins_f):\n",
        "    # Predict gaze\n",
        "    with torch.no_grad():\n",
        "        gaze_f = model.get_gaze(face_f)\n",
        "        gaze_f = gaze_f[0].data.cpu()\n",
        "        display = cv2.circle(display, gaze_origin_f, 1, (0, 255, 0), -1)            \n",
        "        display = utils.draw_gaze(display, gaze_origin_f, gaze_f, length=100, color=(255,0,0), thickness=1)\n",
        "        print(gaze_origin_f)\n",
        "        print(gaze_f)\n",
        "fig=plt.figure(figsize=(10, 10))\n",
        "plt.imshow(display)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_CNcWXgnJkc"
      },
      "source": [
        "def rms_error(x, y):\n",
        "    return np.sqrt(sum(np.square(x - y))/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IXj33zclNJm"
      },
      "source": [
        "# Measures difference in gaze\n",
        "print(rms_error(gaze_u.numpy(), gaze_f.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMmPr0MmnN1h"
      },
      "source": [
        "# TODO\n",
        "# Calculate average difference in gaze over all frames of video"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}